{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96d9409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizerFast, AutoModel, AutoTokenizer\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8057df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0ae1910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "… loaded 5000 sentences\n",
      "… loaded 10000 sentences\n",
      "Done loading: 10000 sentences\n",
      "Shuffled sentences\n",
      "Final: 82243 tokens from 10000 sentences\n",
      "   inst_id  token_id   token punt_inicial punt_final  capitalizacion\n",
      "0        1         0    cómo            ¿                          1\n",
      "1        1         1      va                       ,               0\n",
      "2        1         2   mucha                                       0\n",
      "3        1         3  ##chos                       ,               0\n",
      "4        1         4    todo                                       0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "from typing import List, Optional\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# 1) Loader function\n",
    "def read_raw_sentences(\n",
    "    path: str,\n",
    "    n_max_sentences: Optional[int] = None,\n",
    "    shuffle: bool = False,\n",
    "    random_seed: int = 0,\n",
    "    report_every: int = 10000\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Reads up to `n_max_sentences` lines from `path` (one sentence per line).\n",
    "    Returns a list of the raw lines (with trailing newlines stripped).\n",
    "    \"\"\"\n",
    "    sentences: List[str] = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        if n_max_sentences is not None:\n",
    "            for i in range(n_max_sentences):\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                sentences.append(line.rstrip(\"\\n\"))\n",
    "                if (i + 1) % report_every == 0:\n",
    "                    print(f\"… loaded {i+1} sentences\")\n",
    "        else:\n",
    "            for i, line in enumerate(f, start=1):\n",
    "                sentences.append(line.rstrip(\"\\n\"))\n",
    "                if i % report_every == 0:\n",
    "                    print(f\"… loaded {i} sentences\")\n",
    "    print(f\"Done loading: {len(sentences)} sentences\")\n",
    "    if shuffle:\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(sentences)\n",
    "        print(\"Shuffled sentences\")\n",
    "    return sentences\n",
    "\n",
    "# 2) Your label extractor & pattern\n",
    "pattern = re.compile(r\"\\w+|[^\\w\\s]\", flags=re.UNICODE)\n",
    "\n",
    "def extract_labels(sentence: str):\n",
    "    tokens = pattern.findall(sentence)\n",
    "    words, init_labels, final_labels, cap_labels = [], [], [], []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if re.match(r\"\\w+\", token, flags=re.UNICODE):\n",
    "            # initial punctuation\n",
    "            init = '¿' if i>0 and tokens[i-1]=='¿' else ''\n",
    "            # final punctuation\n",
    "            final = tokens[i+1] if i < len(tokens)-1 and tokens[i+1] in {'.',',','?'} else ''\n",
    "            # capitalization\n",
    "            if token.isupper():\n",
    "                cap = 3\n",
    "            elif token[0].isupper() and token[1:].islower():\n",
    "                cap = 1\n",
    "            elif token.islower():\n",
    "                cap = 0\n",
    "            else:\n",
    "                cap = 2\n",
    "            words.append(token)\n",
    "            init_labels.append(init)\n",
    "            final_labels.append(final)\n",
    "            cap_labels.append(cap)\n",
    "    return words, init_labels, final_labels, cap_labels\n",
    "\n",
    "# 3) Load sentences from file\n",
    "path = \"es_419_validas.txt\"\n",
    "raw_sentences = read_raw_sentences(\n",
    "    path=path,\n",
    "    n_max_sentences=10000,   # or None to load all\n",
    "    shuffle=True,\n",
    "    random_seed=42,\n",
    "    report_every=5000\n",
    ")\n",
    "\n",
    "# 4) Tokenize+label into DataFrame\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "data = []\n",
    "for inst_id, sentence in enumerate(raw_sentences, start=1):\n",
    "    words, init_lbls, final_lbls, cap_lbls = extract_labels(sentence)\n",
    "    token_idx = 0\n",
    "    for word, init_lbl, final_lbl, cap_lbl in zip(words, init_lbls, final_lbls, cap_lbls):\n",
    "        subtokens = tokenizer.tokenize(word.lower())\n",
    "        for i, sub in enumerate(subtokens):\n",
    "            # initial only on first subtoken\n",
    "            punct_init = init_lbl if i == 0 else ''\n",
    "            # final only on last subtoken\n",
    "            punct_final = final_lbl if i == len(subtokens)-1 else ''\n",
    "            data.append([\n",
    "                inst_id,\n",
    "                token_idx,\n",
    "                sub,\n",
    "                punct_init,\n",
    "                punct_final,\n",
    "                cap_lbl\n",
    "            ])\n",
    "            token_idx += 1\n",
    "    if inst_id % 500_000 == 0:\n",
    "        print(f\"… processed {inst_id} sentences, {len(data)} tokens so far\")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\"inst_id\", \"token_id\", \"token\", \"punt_inicial\", \"punt_final\", \"capitalizacion\"]\n",
    ")\n",
    "print(f\"Final: {df.shape[0]} tokens from {inst_id} sentences\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25bfb19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert token strings to BERT token IDs\n",
    "df[\"token_id_bert\"] = tokenizer.convert_tokens_to_ids(df[\"token\"].tolist())\n",
    "\n",
    "# Group by instance to form sequences\n",
    "grouped = {}\n",
    "for inst_id, group in df.groupby(\"inst_id\"):\n",
    "    grouped[inst_id] = {\n",
    "        \"input_ids\": group[\"token_id_bert\"].tolist(),\n",
    "        \"init_labels\": [0 if lbl=='' else 1 for lbl in group[\"punt_inicial\"]],\n",
    "        \"final_labels\": [0 if lbl=='' else (1 if lbl=='.' else (2 if lbl=='?' else 3))\n",
    "                         for lbl in group[\"punt_final\"]],\n",
    "        \"cap_labels\": group[\"capitalizacion\"].tolist(),\n",
    "        \"tokens\": group[\"token\"].tolist()\n",
    "    }\n",
    "\n",
    "# Create a list of instances for splitting\n",
    "instances = list(grouped.values())\n",
    "random.shuffle(instances)\n",
    "n = len(instances)\n",
    "train_split = int(0.8 * n)\n",
    "val_split = int(0.9 * n)\n",
    "train_data = instances[:train_split]\n",
    "val_data   = instances[train_split:val_split]\n",
    "test_data  = instances[val_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f77c7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class PunctCapitalDataset(Dataset):\n",
    "    def __init__(self, instances):\n",
    "        self.instances = instances\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "    def __getitem__(self, idx):\n",
    "        inst = self.instances[idx]\n",
    "        return (\n",
    "            torch.tensor(inst[\"input_ids\"], dtype=torch.long),\n",
    "            torch.tensor(inst[\"init_labels\"], dtype=torch.long),\n",
    "            torch.tensor(inst[\"final_labels\"], dtype=torch.long),\n",
    "            torch.tensor(inst[\"cap_labels\"], dtype=torch.long)\n",
    "        )\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids, init_labs, final_labs, cap_labs = zip(*batch)\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    init_labs  = pad_sequence(init_labs,  batch_first=True, padding_value=-100)\n",
    "    final_labs = pad_sequence(final_labs, batch_first=True, padding_value=-100)\n",
    "    cap_labs   = pad_sequence(cap_labs,   batch_first=True, padding_value=-100)\n",
    "    return input_ids, init_labs, final_labs, cap_labs\n",
    "\n",
    "train_loader = DataLoader(PunctCapitalDataset(train_data), batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(PunctCapitalDataset(val_data), batch_size=128, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10902664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "d_model      = 256\n",
    "nhead        = 8\n",
    "dim_feed     = 512\n",
    "num_layers   = 4\n",
    "dropout      = 0.1\n",
    "max_len      = 512\n",
    "pad_idx      = tokenizer.pad_token_id  # usually 0\n",
    "batch_size   = 32\n",
    "lr           = 5e-4\n",
    "epochs       = 15\n",
    "patience_es  = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae2a0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        d_model=256,\n",
    "        nhead=8,\n",
    "        dim_feedforward=512,\n",
    "        num_layers=4,\n",
    "        max_len=512,\n",
    "        pad_idx=0,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        # embeddings + positional\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n",
    "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "        # transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        # three heads\n",
    "        self.init_head  = nn.Linear(d_model, 2)\n",
    "        self.final_head = nn.Linear(d_model, 4)\n",
    "        self.cap_head   = nn.Linear(d_model, 4)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # input_ids: [B, T]\n",
    "        B, T = input_ids.size()\n",
    "        # token + positional\n",
    "        pos = torch.arange(T, device=input_ids.device).unsqueeze(0).expand(B, T)\n",
    "        x = self.token_emb(input_ids) * math.sqrt(self.d_model)\n",
    "        x = x + self.pos_emb(pos)\n",
    "        # transformer expects [T, B, d_model]\n",
    "        x = self.transformer(\n",
    "            x.transpose(0,1),\n",
    "            src_key_padding_mask=(input_ids == pad_idx)  # mask padded positions\n",
    "        )\n",
    "        x = x.transpose(0,1)  # [B, T, d_model]\n",
    "        return (\n",
    "            self.init_head(x),   # [B, T, 2]\n",
    "            self.final_head(x),  # [B, T, 4]\n",
    "            self.cap_head(x)     # [B, T, 4]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e11dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertPunctCapModel(nn.Module):\n",
    "    def __init__(self,pretrained=\"bert-base-multilingual-cased\"):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(pretrained)\n",
    "        h = self.bert.config.hidden_size\n",
    "        self.h_init = nn.Linear(h,2)\n",
    "        self.h_fin  = nn.Linear(h,4)\n",
    "        self.h_cap  = nn.Linear(h,4)\n",
    "    def forward(self,ids,mask):\n",
    "        out = self.bert(input_ids=ids,attention_mask=mask).last_hidden_state\n",
    "        return self.h_init(out), self.h_fin(out), self.h_cap(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96538790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = CustomTransformerModel(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    dim_feedforward=dim_feed,\n",
    "    num_layers=num_layers,\n",
    "    max_len=max_len,\n",
    "    pad_idx=pad_idx,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "#scheduler = ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27c156eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train loss: 0.7682\n",
      "Epoch 1 — Val loss:   0.6193\n",
      "Epoch 1 — F1 (macro): init=0.791, final=0.549, cap=0.798\n",
      "\n",
      "Initial punctuation per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        no-¿       0.99      1.00      0.99     80562\n",
      "           ¿       0.75      0.48      0.59      1894\n",
      "\n",
      "    accuracy                           0.98     82456\n",
      "   macro avg       0.87      0.74      0.79     82456\n",
      "weighted avg       0.98      0.98      0.98     82456\n",
      "\n",
      "Final punctuation per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.90      0.97      0.93     69267\n",
      "           .       0.60      0.42      0.50      7645\n",
      "           ?       0.64      0.36      0.46      1945\n",
      "           ,       0.74      0.19      0.31      3599\n",
      "\n",
      "    accuracy                           0.87     82456\n",
      "   macro avg       0.72      0.49      0.55     82456\n",
      "weighted avg       0.86      0.87      0.86     82456\n",
      "\n",
      "Capitalization per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       lower       0.93      0.98      0.96     64112\n",
      "     Initial       0.92      0.75      0.83     17468\n",
      "       Mixed       0.82      0.49      0.61       271\n",
      "      ALLCAP       0.91      0.71      0.80       605\n",
      "\n",
      "    accuracy                           0.93     82456\n",
      "   macro avg       0.89      0.73      0.80     82456\n",
      "weighted avg       0.93      0.93      0.93     82456\n",
      "\n",
      "------------------------------------------------------------\n",
      "Epoch 2 — Train loss: 0.5914\n",
      "Epoch 2 — Val loss:   0.5498\n",
      "Epoch 2 — F1 (macro): init=0.797, final=0.601, cap=0.830\n",
      "\n",
      "Initial punctuation per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        no-¿       0.99      1.00      0.99     80562\n",
      "           ¿       0.80      0.48      0.60      1894\n",
      "\n",
      "    accuracy                           0.99     82456\n",
      "   macro avg       0.89      0.74      0.80     82456\n",
      "weighted avg       0.98      0.99      0.98     82456\n",
      "\n",
      "Final punctuation per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.91      0.97      0.94     69267\n",
      "           .       0.62      0.55      0.58      7645\n",
      "           ?       0.70      0.37      0.49      1945\n",
      "           ,       0.74      0.27      0.39      3599\n",
      "\n",
      "    accuracy                           0.88     82456\n",
      "   macro avg       0.74      0.54      0.60     82456\n",
      "weighted avg       0.87      0.88      0.87     82456\n",
      "\n",
      "Capitalization per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       lower       0.95      0.98      0.97     64112\n",
      "     Initial       0.92      0.82      0.87     17468\n",
      "       Mixed       0.67      0.69      0.68       271\n",
      "      ALLCAP       0.86      0.76      0.81       605\n",
      "\n",
      "    accuracy                           0.94     82456\n",
      "   macro avg       0.85      0.81      0.83     82456\n",
      "weighted avg       0.94      0.94      0.94     82456\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "for epoch in range(1, 1+2):  # e.g. 5 epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    n_batches = 0\n",
    "    for input_ids, init_labs, final_labs, cap_labs in train_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        init_labs  = init_labs.to(device)\n",
    "        final_labs = final_labs.to(device)\n",
    "        cap_labs   = cap_labs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        init_logits, final_logits, cap_logits = model(input_ids)\n",
    "\n",
    "        loss_init  = criterion(init_logits.view(-1, 2),  init_labs.view(-1))\n",
    "        loss_final = criterion(final_logits.view(-1, 4), final_labs.view(-1))\n",
    "        loss_cap   = criterion(cap_logits.view(-1, 4),   cap_labs.view(-1))\n",
    "        loss = loss_init + loss_final + loss_cap\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    avg_train_loss = running_loss / n_batches\n",
    "    print(f\"Epoch {epoch} — Train loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    n_val_batches = 0\n",
    "\n",
    "    all_init_trues,  all_init_preds  = [], []\n",
    "    all_final_trues, all_final_preds = [], []\n",
    "    all_cap_trues,   all_cap_preds   = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, init_labs, final_labs, cap_labs in val_loader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            init_labs  = init_labs.to(device)\n",
    "            final_labs = final_labs.to(device)\n",
    "            cap_labs   = cap_labs.to(device)\n",
    "\n",
    "            init_logits, final_logits, cap_logits = model(input_ids)\n",
    "\n",
    "            # compute val loss\n",
    "            loss_init  = criterion(init_logits.view(-1, 2),  init_labs.view(-1))\n",
    "            loss_final = criterion(final_logits.view(-1, 4), final_labs.view(-1))\n",
    "            loss_cap   = criterion(cap_logits.view(-1, 4),   cap_labs.view(-1))\n",
    "            loss = loss_init + loss_final + loss_cap\n",
    "            val_loss += loss.item()\n",
    "            n_val_batches += 1\n",
    "\n",
    "            # get predictions\n",
    "            init_preds  = init_logits.argmax(dim=-1)\n",
    "            final_preds = final_logits.argmax(dim=-1)\n",
    "            cap_preds   = cap_logits.argmax(dim=-1)\n",
    "\n",
    "            # mask out padding (-100)\n",
    "            mask_init  = (init_labs.view(-1)  != -100)\n",
    "            mask_final = (final_labs.view(-1) != -100)\n",
    "            mask_cap   = (cap_labs.view(-1)   != -100)\n",
    "\n",
    "            all_init_trues.extend(init_labs.view(-1)[mask_init].cpu().tolist())\n",
    "            all_init_preds.extend(init_preds.view(-1)[mask_init].cpu().tolist())\n",
    "            all_final_trues.extend(final_labs.view(-1)[mask_final].cpu().tolist())\n",
    "            all_final_preds.extend(final_preds.view(-1)[mask_final].cpu().tolist())\n",
    "            all_cap_trues.extend(cap_labs.view(-1)[mask_cap].cpu().tolist())\n",
    "            all_cap_preds.extend(cap_preds.view(-1)[mask_cap].cpu().tolist())\n",
    "\n",
    "    avg_val_loss = val_loss / n_val_batches\n",
    "    print(f\"Epoch {epoch} — Val loss:   {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Compute macro-F1\n",
    "    f1_init_macro  = f1_score(all_init_trues,  all_init_preds,  average='macro', zero_division=0)\n",
    "    f1_final_macro = f1_score(all_final_trues, all_final_preds, average='macro', zero_division=0)\n",
    "    f1_cap_macro   = f1_score(all_cap_trues,   all_cap_preds,   average='macro', zero_division=0)\n",
    "    print(f\"Epoch {epoch} — F1 (macro): init={f1_init_macro:.3f}, final={f1_final_macro:.3f}, cap={f1_cap_macro:.3f}\")\n",
    "\n",
    "    # Per-class F1 reports\n",
    "    print(\"\\nInitial punctuation per-class F1:\")\n",
    "    print(classification_report(all_init_trues, all_init_preds, labels=[0,1], target_names=['no-¿','¿'], zero_division=0))\n",
    "\n",
    "    print(\"Final punctuation per-class F1:\")\n",
    "    print(classification_report(all_final_trues, all_final_preds,\n",
    "                                labels=[0,1,2,3],\n",
    "                                target_names=['none','.', '?', ','], zero_division=0))\n",
    "\n",
    "    print(\"Capitalization per-class F1:\")\n",
    "    print(classification_report(all_cap_trues, all_cap_preds,\n",
    "                                labels=[0,1,2,3],\n",
    "                                target_names=['lower','Initial','Mixed','ALLCAP'], zero_division=0))\n",
    "\n",
    "    print(\"-\"*60) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f7855cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote predictions.csv\n",
      "Test set performance:\n",
      "  • Initial punctuation F1-macro: 0.7848\n",
      "  • Final punctuation   F1-macro: 0.5956\n",
      "  • Capitalization      F1-macro: 0.8345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model.eval()\n",
    "output_rows = []\n",
    "\n",
    "# For metric accumulation\n",
    "all_init_trues,  all_init_preds  = [], [] \n",
    "all_final_trues, all_final_preds = [], []\n",
    "all_cap_trues,   all_cap_preds   = [], []\n",
    "\n",
    "idx_map_init    = {0:'', 1:'¿'}\n",
    "idx_map_final   = {0:'', 1:'.', 2:'?', 3:','}\n",
    "\n",
    "for inst_id, instance in enumerate(test_data):\n",
    "    # prepare inputs\n",
    "    input_ids = torch.tensor(instance[\"input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        init_logits, final_logits, cap_logits = model(input_ids)\n",
    "\n",
    "    # get token-level preds\n",
    "    init_pred  = init_logits.argmax(dim=-1).squeeze(0).cpu().tolist()\n",
    "    final_pred = final_logits.argmax(dim=-1).squeeze(0).cpu().tolist()\n",
    "    cap_pred   = cap_logits.argmax(dim=-1).squeeze(0).cpu().tolist()\n",
    "\n",
    "    # retrieve true labels\n",
    "    init_true  = instance[\"init_labels\"]\n",
    "    final_true = instance[\"final_labels\"]\n",
    "    cap_true   = instance[\"cap_labels\"]\n",
    "    tokens     = instance[\"tokens\"]\n",
    "\n",
    "    # sanity check\n",
    "    assert len(init_pred)==len(init_true)==len(tokens)\n",
    "\n",
    "    # accumulate and record\n",
    "    for token_idx, token in enumerate(tokens):\n",
    "        # append to CSV rows\n",
    "        output_rows.append({\n",
    "            \"instancia_id\": inst_id,\n",
    "            \"token_id\":     token_idx,\n",
    "            \"token\":        token,\n",
    "            \"punt_inicial\": idx_map_init[init_pred[token_idx]],\n",
    "            \"punt_final\":   idx_map_final[final_pred[token_idx]],\n",
    "            \"capitalizacion\": cap_pred[token_idx]\n",
    "        })\n",
    "        # accumulate for metrics\n",
    "        all_init_trues.append(init_true[token_idx])\n",
    "        all_init_preds.append(init_pred[token_idx])\n",
    "        all_final_trues.append(final_true[token_idx])\n",
    "        all_final_preds.append(final_pred[token_idx])\n",
    "        all_cap_trues.append(cap_true[token_idx])\n",
    "        all_cap_preds.append(cap_pred[token_idx])\n",
    "\n",
    "# build and save DataFrame\n",
    "output_df = pd.DataFrame(output_rows)\n",
    "output_df.to_csv(\"predictions.csv\", index=False)\n",
    "print(\"Wrote predictions.csv\")\n",
    "\n",
    "# compute and print macro-F1 for each task\n",
    "f1_init  = f1_score(all_init_trues,  all_init_preds,  average=\"macro\", zero_division=0)\n",
    "f1_final = f1_score(all_final_trues, all_final_preds, average=\"macro\", zero_division=0)\n",
    "f1_cap   = f1_score(all_cap_trues,   all_cap_preds,   average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"Test set performance:\")\n",
    "print(f\"  • Initial punctuation F1-macro: {f1_init:.4f}\")\n",
    "print(f\"  • Final punctuation   F1-macro: {f1_final:.4f}\")\n",
    "print(f\"  • Capitalization      F1-macro: {f1_cap:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc14bc9",
   "metadata": {},
   "source": [
    "# Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa152c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertPunctCapModel(nn.Module):\n",
    "    def __init__(self,pretrained=\"bert-base-multilingual-cased\"):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(pretrained)\n",
    "        h = self.bert.config.hidden_size\n",
    "        self.h_init = nn.Linear(h,2)\n",
    "        self.h_fin  = nn.Linear(h,4)\n",
    "        self.h_cap  = nn.Linear(h,4)\n",
    "    def forward(self,ids,mask):\n",
    "        out = self.bert(input_ids=ids,attention_mask=mask).last_hidden_state\n",
    "        return self.h_init(out), self.h_fin(out), self.h_cap(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64dae5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =BertPunctCapModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "#scheduler = ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24d7c51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train loss: 1.5490\n",
      "Epoch 1 — Val loss:   1.2930\n",
      "Epoch 1 — F1 (macro): init=0.494, final=0.228, cap=0.219\n",
      "Initial punctuation per-class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        no-¿       0.98      1.00      0.99      8075\n",
      "           ¿       0.00      0.00      0.00       204\n",
      "\n",
      "    accuracy                           0.98      8279\n",
      "   macro avg       0.49      0.50      0.49      8279\n",
      "weighted avg       0.95      0.98      0.96      8279\n",
      "\n",
      "Final punctuation per-class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.84      1.00      0.91      6948\n",
      "           .       0.00      0.00      0.00       757\n",
      "          ?        0.00      0.00      0.00       205\n",
      "           ,       0.00      0.00      0.00       369\n",
      "\n",
      "    accuracy                           0.84      8279\n",
      "   macro avg       0.21      0.25      0.23      8279\n",
      "weighted avg       0.70      0.84      0.77      8279\n",
      "\n",
      "Capitalization per-class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       lower       0.78      1.00      0.88      6451\n",
      "     Initial       0.00      0.00      0.00      1752\n",
      "       Mixed       0.00      0.00      0.00        21\n",
      "      ALLCAP       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.78      8279\n",
      "   macro avg       0.19      0.25      0.22      8279\n",
      "weighted avg       0.61      0.78      0.68      8279\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     32\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 34\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m — Train loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_train_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "for epoch in range(1, 1+2):  # e.g. 2 epochs\n",
    "    # —— TRAIN —— \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input_ids, init_labs, final_labs, cap_labs in train_loader:\n",
    "        # move to device\n",
    "        input_ids = input_ids.to(device)\n",
    "        init_labs  = init_labs.to(device)\n",
    "        final_labs = final_labs.to(device)\n",
    "        cap_labs   = cap_labs.to(device)\n",
    "\n",
    "        # build attention mask (1 for real tokens, 0 for pad)\n",
    "        attention_mask = (input_ids != tokenizer.pad_token_id).long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: note the two arguments\n",
    "        init_logits, final_logits, cap_logits = model(input_ids, attention_mask)\n",
    "\n",
    "        # compute losses\n",
    "        loss_init  = criterion(init_logits.view(-1, 2),  init_labs.view(-1))\n",
    "        loss_final = criterion(final_logits.view(-1, 4), final_labs.view(-1))\n",
    "        loss_cap   = criterion(cap_logits.view(-1, 4),   cap_labs.view(-1))\n",
    "        loss = loss_init + loss_final + loss_cap\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch} — Train loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # —— VALIDATION —— \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    all_init_trues,  all_init_preds  = [], []\n",
    "    all_final_trues, all_final_preds = [], []\n",
    "    all_cap_trues,   all_cap_preds   = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, init_labs, final_labs, cap_labs in val_loader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            init_labs  = init_labs.to(device)\n",
    "            final_labs = final_labs.to(device)\n",
    "            cap_labs   = cap_labs.to(device)\n",
    "\n",
    "            attention_mask = (input_ids != tokenizer.pad_token_id).long().to(device)\n",
    "            init_logits, final_logits, cap_logits = model(input_ids, attention_mask)\n",
    "\n",
    "            # validation loss\n",
    "            loss_init  = criterion(init_logits.view(-1, 2),  init_labs.view(-1))\n",
    "            loss_final = criterion(final_logits.view(-1, 4), final_labs.view(-1))\n",
    "            loss_cap   = criterion(cap_logits.view(-1, 4),   cap_labs.view(-1))\n",
    "            val_loss  += (loss_init + loss_final + loss_cap).item()\n",
    "\n",
    "            # predictions\n",
    "            init_preds  = init_logits.argmax(dim=-1)\n",
    "            final_preds = final_logits.argmax(dim=-1)\n",
    "            cap_preds   = cap_logits.argmax(dim=-1)\n",
    "\n",
    "            # mask out padding positions\n",
    "            mask_init  = init_labs.view(-1)  != -100\n",
    "            mask_final = final_labs.view(-1) != -100\n",
    "            mask_cap   = cap_labs.view(-1)   != -100\n",
    "\n",
    "            all_init_trues.extend(init_labs.view(-1)[mask_init].cpu().tolist())\n",
    "            all_init_preds.extend(init_preds.view(-1)[mask_init].cpu().tolist())\n",
    "            all_final_trues.extend(final_labs.view(-1)[mask_final].cpu().tolist())\n",
    "            all_final_preds.extend(final_preds.view(-1)[mask_final].cpu().tolist())\n",
    "            all_cap_trues.extend(cap_labs.view(-1)[mask_cap].cpu().tolist())\n",
    "            all_cap_preds.extend(cap_preds.view(-1)[mask_cap].cpu().tolist())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch} — Val loss:   {avg_val_loss:.4f}\")\n",
    "\n",
    "    # compute macro-F1\n",
    "    f1_init = f1_score(all_init_trues, all_init_preds, average='macro', zero_division=0)\n",
    "    f1_final = f1_score(all_final_trues, all_final_preds, average='macro', zero_division=0)\n",
    "    f1_cap = f1_score(all_cap_trues, all_cap_preds, average='macro', zero_division=0)\n",
    "    print(f\"Epoch {epoch} — F1 (macro): init={f1_init:.3f}, final={f1_final:.3f}, cap={f1_cap:.3f}\")\n",
    "\n",
    "    # per-class reports (optional)\n",
    "    print(\"Initial punctuation per-class:\")\n",
    "    print(classification_report(all_init_trues, all_init_preds, labels=[0,1], target_names=['no-¿','¿'], zero_division=0))\n",
    "    print(\"Final punctuation per-class:\")\n",
    "    print(classification_report(all_final_trues, all_final_preds, labels=[0,1,2,3], target_names=['none','.','? ',','], zero_division=0))\n",
    "    print(\"Capitalization per-class:\")\n",
    "    print(classification_report(all_cap_trues, all_cap_preds, labels=[0,1,2,3], target_names=['lower','Initial','Mixed','ALLCAP'], zero_division=0))\n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a98621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model.eval()\n",
    "output_rows = []\n",
    "\n",
    "# For metric accumulation\n",
    "all_init_trues,  all_init_preds  = [], [] \n",
    "all_final_trues, all_final_preds = [], []\n",
    "all_cap_trues,   all_cap_preds   = [], []\n",
    "\n",
    "idx_map_init    = {0:'', 1:'¿'}\n",
    "idx_map_final   = {0:'', 1:'.', 2:'?', 3:','}\n",
    "\n",
    "for inst_id, instance in enumerate(test_data):\n",
    "    # prepare inputs\n",
    "    input_ids = torch.tensor(instance[\"input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        init_logits, final_logits, cap_logits = model(input_ids)\n",
    "\n",
    "    # get token-level preds\n",
    "    init_pred  = init_logits.argmax(dim=-1).squeeze(0).cpu().tolist()\n",
    "    final_pred = final_logits.argmax(dim=-1).squeeze(0).cpu().tolist()\n",
    "    cap_pred   = cap_logits.argmax(dim=-1).squeeze(0).cpu().tolist()\n",
    "\n",
    "    # retrieve true labels\n",
    "    init_true  = instance[\"init_labels\"]\n",
    "    final_true = instance[\"final_labels\"]\n",
    "    cap_true   = instance[\"cap_labels\"]\n",
    "    tokens     = instance[\"tokens\"]\n",
    "\n",
    "    # sanity check\n",
    "    assert len(init_pred)==len(init_true)==len(tokens)\n",
    "\n",
    "    # accumulate and record\n",
    "    for token_idx, token in enumerate(tokens):\n",
    "        # append to CSV rows\n",
    "        output_rows.append({\n",
    "            \"instancia_id\": inst_id,\n",
    "            \"token_id\":     token_idx,\n",
    "            \"token\":        token,\n",
    "            \"punt_inicial\": idx_map_init[init_pred[token_idx]],\n",
    "            \"punt_final\":   idx_map_final[final_pred[token_idx]],\n",
    "            \"capitalizacion\": cap_pred[token_idx]\n",
    "        })\n",
    "        # accumulate for metrics\n",
    "        all_init_trues.append(init_true[token_idx])\n",
    "        all_init_preds.append(init_pred[token_idx])\n",
    "        all_final_trues.append(final_true[token_idx])\n",
    "        all_final_preds.append(final_pred[token_idx])\n",
    "        all_cap_trues.append(cap_true[token_idx])\n",
    "        all_cap_preds.append(cap_pred[token_idx])\n",
    "\n",
    "# build and save DataFrame\n",
    "output_df = pd.DataFrame(output_rows)\n",
    "output_df.to_csv(\"predictions.csv\", index=False)\n",
    "print(\"Wrote predictions.csv\")\n",
    "\n",
    "# compute and print macro-F1 for each task\n",
    "f1_init  = f1_score(all_init_trues,  all_init_preds,  average=\"macro\", zero_division=0)\n",
    "f1_final = f1_score(all_final_trues, all_final_preds, average=\"macro\", zero_division=0)\n",
    "f1_cap   = f1_score(all_cap_trues,   all_cap_preds,   average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"Test set performance:\")\n",
    "print(f\"  • Initial punctuation F1-macro: {f1_init:.4f}\")\n",
    "print(f\"  • Final punctuation   F1-macro: {f1_final:.4f}\")\n",
    "print(f\"  • Capitalization      F1-macro: {f1_cap:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
