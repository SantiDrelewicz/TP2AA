{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96d9409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizerFast, AutoModel, AutoTokenizer\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ae1910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "… loaded 100000 sentences\n",
      "… loaded 200000 sentences\n",
      "… loaded 300000 sentences\n",
      "… loaded 400000 sentences\n",
      "… loaded 500000 sentences\n",
      "Done loading: 500000 sentences\n",
      "Shuffled sentences\n",
      "… processed 500000 sentences, 4096405 tokens so far\n",
      "Final: 4096405 tokens from 500000 sentences\n",
      "   inst_id  token_id  token punt_inicial punt_final  capitalizacion\n",
      "0        1         0    qui                                       1\n",
      "1        1         1  ##ero                                       1\n",
      "2        1         2  vivir                                       0\n",
      "3        2         0     es                                       1\n",
      "4        2         1    una                                       0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "from typing import List, Optional\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# 1) Loader function\n",
    "def read_raw_sentences(\n",
    "    path: str,\n",
    "    n_max_sentences: Optional[int] = None,\n",
    "    shuffle: bool = False,\n",
    "    random_seed: int = 0,\n",
    "    report_every: int = 10000\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Reads up to `n_max_sentences` lines from `path` (one sentence per line).\n",
    "    Returns a list of the raw lines (with trailing newlines stripped).\n",
    "    \"\"\"\n",
    "    sentences: List[str] = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        if n_max_sentences is not None:\n",
    "            for i in range(n_max_sentences):\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                sentences.append(line.rstrip(\"\\n\"))\n",
    "                if (i + 1) % report_every == 0:\n",
    "                    print(f\"… loaded {i+1} sentences\")\n",
    "        else:\n",
    "            for i, line in enumerate(f, start=1):\n",
    "                sentences.append(line.rstrip(\"\\n\"))\n",
    "                if i % report_every == 0:\n",
    "                    print(f\"… loaded {i} sentences\")\n",
    "    print(f\"Done loading: {len(sentences)} sentences\")\n",
    "    if shuffle:\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(sentences)\n",
    "        print(\"Shuffled sentences\")\n",
    "    return sentences\n",
    "\n",
    "# 2) Your label extractor & pattern\n",
    "pattern = re.compile(r\"\\w+|[^\\w\\s]\", flags=re.UNICODE)\n",
    "\n",
    "def extract_labels(sentence: str):\n",
    "    tokens = pattern.findall(sentence)\n",
    "    words, init_labels, final_labels, cap_labels = [], [], [], []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if re.match(r\"\\w+\", token, flags=re.UNICODE):\n",
    "            # initial punctuation\n",
    "            init = '¿' if i>0 and tokens[i-1]=='¿' else ''\n",
    "            # final punctuation\n",
    "            final = tokens[i+1] if i < len(tokens)-1 and tokens[i+1] in {'.',',','?'} else ''\n",
    "            # capitalization\n",
    "            if token.isupper():\n",
    "                cap = 3\n",
    "            elif token[0].isupper() and token[1:].islower():\n",
    "                cap = 1\n",
    "            elif token.islower():\n",
    "                cap = 0\n",
    "            else:\n",
    "                cap = 2\n",
    "            words.append(token)\n",
    "            init_labels.append(init)\n",
    "            final_labels.append(final)\n",
    "            cap_labels.append(cap)\n",
    "    return words, init_labels, final_labels, cap_labels\n",
    "\n",
    "# 3) Load sentences from file\n",
    "path = \"es_419_validas.txt\"\n",
    "raw_sentences = read_raw_sentences(\n",
    "    path=path,\n",
    "    n_max_sentences=500000,   # or None to load all\n",
    "    shuffle=True,\n",
    "    random_seed=42,\n",
    "    report_every=100000\n",
    ")\n",
    "\n",
    "# 4) Tokenize+label into DataFrame\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "data = []\n",
    "for inst_id, sentence in enumerate(raw_sentences, start=1):\n",
    "    words, init_lbls, final_lbls, cap_lbls = extract_labels(sentence)\n",
    "    token_idx = 0\n",
    "    for word, init_lbl, final_lbl, cap_lbl in zip(words, init_lbls, final_lbls, cap_lbls):\n",
    "        subtokens = tokenizer.tokenize(word.lower())\n",
    "        for i, sub in enumerate(subtokens):\n",
    "            # initial only on first subtoken\n",
    "            punct_init = init_lbl if i == 0 else ''\n",
    "            # final only on last subtoken\n",
    "            punct_final = final_lbl if i == len(subtokens)-1 else ''\n",
    "            data.append([\n",
    "                inst_id,\n",
    "                token_idx,\n",
    "                sub,\n",
    "                punct_init,\n",
    "                punct_final,\n",
    "                cap_lbl\n",
    "            ])\n",
    "            token_idx += 1\n",
    "    if inst_id % 500_000 == 0:\n",
    "        print(f\"… processed {inst_id} sentences, {len(data)} tokens so far\")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\"inst_id\", \"token_id\", \"token\", \"punt_inicial\", \"punt_final\", \"capitalizacion\"]\n",
    ")\n",
    "print(f\"Final: {df.shape[0]} tokens from {inst_id} sentences\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bfb19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert token strings to BERT token IDs\n",
    "df[\"token_id_bert\"] = tokenizer.convert_tokens_to_ids(df[\"token\"].tolist())\n",
    "\n",
    "# Group by instance to form sequences\n",
    "grouped = {}\n",
    "for inst_id, group in df.groupby(\"inst_id\"):\n",
    "    grouped[inst_id] = {\n",
    "        \"input_ids\": group[\"token_id_bert\"].tolist(),\n",
    "        \"init_labels\": [0 if lbl=='' else 1 for lbl in group[\"punt_inicial\"]],\n",
    "        \"final_labels\": [0 if lbl=='' else (1 if lbl=='.' else (2 if lbl=='?' else 3))\n",
    "                         for lbl in group[\"punt_final\"]],\n",
    "        \"cap_labels\": group[\"capitalizacion\"].tolist(),\n",
    "        \"tokens\": group[\"token\"].tolist()\n",
    "    }\n",
    "\n",
    "# Create a list of instances for splitting\n",
    "instances = list(grouped.values())\n",
    "random.shuffle(instances)\n",
    "n = len(instances)\n",
    "train_split = int(0.8 * n)\n",
    "val_split = int(0.9 * n)\n",
    "train_data = instances[:train_split]\n",
    "val_data   = instances[train_split:val_split]\n",
    "test_data  = instances[val_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77c7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class PunctCapitalDataset(Dataset):\n",
    "    def __init__(self, instances):\n",
    "        self.instances = instances\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "    def __getitem__(self, idx):\n",
    "        inst = self.instances[idx]\n",
    "        return (\n",
    "            torch.tensor(inst[\"input_ids\"], dtype=torch.long),\n",
    "            torch.tensor(inst[\"init_labels\"], dtype=torch.long),\n",
    "            torch.tensor(inst[\"final_labels\"], dtype=torch.long),\n",
    "            torch.tensor(inst[\"cap_labels\"], dtype=torch.long)\n",
    "        )\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids, init_labs, final_labs, cap_labs = zip(*batch)\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    init_labs  = pad_sequence(init_labs,  batch_first=True, padding_value=-100)\n",
    "    final_labs = pad_sequence(final_labs, batch_first=True, padding_value=-100)\n",
    "    cap_labs   = pad_sequence(cap_labs,   batch_first=True, padding_value=-100)\n",
    "    return input_ids, init_labs, final_labs, cap_labs\n",
    "\n",
    "train_loader = DataLoader(PunctCapitalDataset(train_data), batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(PunctCapitalDataset(val_data), batch_size=128, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98471449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class JointPunctCapitalRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_init: int,\n",
    "        num_final: int,\n",
    "        num_cap: int,\n",
    "        n_layers: int = 1,\n",
    "        dropout: float = 0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Embedding + input dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.input_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Bidirectional RNN\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim // 2,\n",
    "            num_layers=n_layers,\n",
    "            dropout=dropout if n_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Output dropout before heads\n",
    "        self.output_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Three classification heads\n",
    "        self.init_head = nn.Linear(hidden_dim, num_init)\n",
    "        self.final_head = nn.Linear(hidden_dim, num_final)\n",
    "        self.cap_head = nn.Linear(hidden_dim, num_cap)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T]\n",
    "        emb = self.embedding(x)           # [B, T, E]\n",
    "        emb = self.input_dropout(emb)\n",
    "\n",
    "        out, _ = self.rnn(emb)            # [B, T, H]\n",
    "        out = self.output_dropout(out)\n",
    "\n",
    "        init_logits = self.init_head(out)      # [B, T, num_init]\n",
    "        final_logits = self.final_head(out)    # [B, T, num_final]\n",
    "        cap_logits = self.cap_head(out)        # [B, T, num_cap]\n",
    "\n",
    "        return init_logits, final_logits, cap_logits\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = JointPunctCapitalRNN(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_init=2,\n",
    "    num_final=4,\n",
    "    num_cap=4,\n",
    "    n_layers=2,\n",
    "    dropout=0.1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bacbe569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train loss: 0.3898\n",
      "Epoch 1 — Val loss:   0.2884\n",
      "Epoch 1 — F1 (macro): init=0.838, final=0.789, cap=0.891\n",
      "\n",
      "Initial punctuation per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        no-¿       0.99      1.00      0.99    400149\n",
      "           ¿       0.83      0.58      0.68      9561\n",
      "\n",
      "    accuracy                           0.99    409710\n",
      "   macro avg       0.91      0.79      0.84    409710\n",
      "weighted avg       0.99      0.99      0.99    409710\n",
      "\n",
      "Final punctuation per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.97      0.99      0.98    344383\n",
      "           .       0.84      0.95      0.89     37987\n",
      "           ?       0.82      0.61      0.70      9719\n",
      "           ,       0.81      0.46      0.59     17621\n",
      "\n",
      "    accuracy                           0.95    409710\n",
      "   macro avg       0.86      0.75      0.79    409710\n",
      "weighted avg       0.95      0.95      0.95    409710\n",
      "\n",
      "Capitalization per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       lower       0.97      0.99      0.98    318947\n",
      "     Initial       0.97      0.89      0.93     86350\n",
      "       Mixed       0.94      0.68      0.79      1453\n",
      "      ALLCAP       0.97      0.77      0.86      2960\n",
      "\n",
      "    accuracy                           0.97    409710\n",
      "   macro avg       0.96      0.84      0.89    409710\n",
      "weighted avg       0.97      0.97      0.97    409710\n",
      "\n",
      "------------------------------------------------------------\n",
      "Epoch 2 — Train loss: 0.2784\n",
      "Epoch 2 — Val loss:   0.2544\n",
      "Epoch 2 — F1 (macro): init=0.839, final=0.806, cap=0.918\n",
      "\n",
      "Initial punctuation per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        no-¿       0.99      1.00      0.99    400149\n",
      "           ¿       0.87      0.56      0.68      9561\n",
      "\n",
      "    accuracy                           0.99    409710\n",
      "   macro avg       0.93      0.78      0.84    409710\n",
      "weighted avg       0.99      0.99      0.99    409710\n",
      "\n",
      "Final punctuation per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.98      0.98      0.98    344383\n",
      "           .       0.83      0.97      0.89     37987\n",
      "           ?       0.91      0.56      0.69      9719\n",
      "           ,       0.80      0.55      0.66     17621\n",
      "\n",
      "    accuracy                           0.95    409710\n",
      "   macro avg       0.88      0.77      0.81    409710\n",
      "weighted avg       0.95      0.95      0.95    409710\n",
      "\n",
      "Capitalization per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       lower       0.98      0.99      0.99    318947\n",
      "     Initial       0.97      0.93      0.95     86350\n",
      "       Mixed       0.96      0.76      0.85      1453\n",
      "      ALLCAP       0.93      0.85      0.89      2960\n",
      "\n",
      "    accuracy                           0.98    409710\n",
      "   macro avg       0.96      0.88      0.92    409710\n",
      "weighted avg       0.98      0.98      0.98    409710\n",
      "\n",
      "------------------------------------------------------------\n",
      "Epoch 3 — Train loss: 0.2531\n",
      "Epoch 3 — Val loss:   0.2386\n",
      "Epoch 3 — F1 (macro): init=0.855, final=0.823, cap=0.927\n",
      "\n",
      "Initial punctuation per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        no-¿       0.99      1.00      0.99    400149\n",
      "           ¿       0.85      0.62      0.72      9561\n",
      "\n",
      "    accuracy                           0.99    409710\n",
      "   macro avg       0.92      0.81      0.86    409710\n",
      "weighted avg       0.99      0.99      0.99    409710\n",
      "\n",
      "Final punctuation per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.98      0.98      0.98    344383\n",
      "           .       0.84      0.96      0.90     37987\n",
      "           ?       0.86      0.63      0.73      9719\n",
      "           ,       0.78      0.60      0.68     17621\n",
      "\n",
      "    accuracy                           0.96    409710\n",
      "   macro avg       0.87      0.80      0.82    409710\n",
      "weighted avg       0.96      0.96      0.95    409710\n",
      "\n",
      "Capitalization per-class F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       lower       0.98      0.99      0.99    318947\n",
      "     Initial       0.98      0.93      0.95     86350\n",
      "       Mixed       0.96      0.79      0.87      1453\n",
      "      ALLCAP       0.95      0.85      0.90      2960\n",
      "\n",
      "    accuracy                           0.98    409710\n",
      "   macro avg       0.97      0.89      0.93    409710\n",
      "weighted avg       0.98      0.98      0.98    409710\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "for epoch in range(1, 1+3):  # e.g. 5 epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    n_batches = 0\n",
    "    for input_ids, init_labs, final_labs, cap_labs in train_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        init_labs  = init_labs.to(device)\n",
    "        final_labs = final_labs.to(device)\n",
    "        cap_labs   = cap_labs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        init_logits, final_logits, cap_logits = model(input_ids)\n",
    "\n",
    "        loss_init  = criterion(init_logits.view(-1, 2),  init_labs.view(-1))\n",
    "        loss_final = criterion(final_logits.view(-1, 4), final_labs.view(-1))\n",
    "        loss_cap   = criterion(cap_logits.view(-1, 4),   cap_labs.view(-1))\n",
    "        loss = loss_init + loss_final + loss_cap\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    avg_train_loss = running_loss / n_batches\n",
    "    print(f\"Epoch {epoch} — Train loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    n_val_batches = 0\n",
    "\n",
    "    all_init_trues,  all_init_preds  = [], []\n",
    "    all_final_trues, all_final_preds = [], []\n",
    "    all_cap_trues,   all_cap_preds   = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, init_labs, final_labs, cap_labs in val_loader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            init_labs  = init_labs.to(device)\n",
    "            final_labs = final_labs.to(device)\n",
    "            cap_labs   = cap_labs.to(device)\n",
    "\n",
    "            init_logits, final_logits, cap_logits = model(input_ids)\n",
    "\n",
    "            # compute val loss\n",
    "            loss_init  = criterion(init_logits.view(-1, 2),  init_labs.view(-1))\n",
    "            loss_final = criterion(final_logits.view(-1, 4), final_labs.view(-1))\n",
    "            loss_cap   = criterion(cap_logits.view(-1, 4),   cap_labs.view(-1))\n",
    "            loss = loss_init + loss_final + loss_cap\n",
    "            val_loss += loss.item()\n",
    "            n_val_batches += 1\n",
    "\n",
    "            # get predictions\n",
    "            init_preds  = init_logits.argmax(dim=-1)\n",
    "            final_preds = final_logits.argmax(dim=-1)\n",
    "            cap_preds   = cap_logits.argmax(dim=-1)\n",
    "\n",
    "            # mask out padding (-100)\n",
    "            mask_init  = (init_labs.view(-1)  != -100)\n",
    "            mask_final = (final_labs.view(-1) != -100)\n",
    "            mask_cap   = (cap_labs.view(-1)   != -100)\n",
    "\n",
    "            all_init_trues.extend(init_labs.view(-1)[mask_init].cpu().tolist())\n",
    "            all_init_preds.extend(init_preds.view(-1)[mask_init].cpu().tolist())\n",
    "            all_final_trues.extend(final_labs.view(-1)[mask_final].cpu().tolist())\n",
    "            all_final_preds.extend(final_preds.view(-1)[mask_final].cpu().tolist())\n",
    "            all_cap_trues.extend(cap_labs.view(-1)[mask_cap].cpu().tolist())\n",
    "            all_cap_preds.extend(cap_preds.view(-1)[mask_cap].cpu().tolist())\n",
    "\n",
    "    avg_val_loss = val_loss / n_val_batches\n",
    "    print(f\"Epoch {epoch} — Val loss:   {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Compute macro-F1\n",
    "    f1_init_macro  = f1_score(all_init_trues,  all_init_preds,  average='macro', zero_division=0)\n",
    "    f1_final_macro = f1_score(all_final_trues, all_final_preds, average='macro', zero_division=0)\n",
    "    f1_cap_macro   = f1_score(all_cap_trues,   all_cap_preds,   average='macro', zero_division=0)\n",
    "    print(f\"Epoch {epoch} — F1 (macro): init={f1_init_macro:.3f}, final={f1_final_macro:.3f}, cap={f1_cap_macro:.3f}\")\n",
    "\n",
    "    # Per-class F1 reports\n",
    "    print(\"\\nInitial punctuation per-class F1:\")\n",
    "    print(classification_report(all_init_trues, all_init_preds, labels=[0,1], target_names=['no-¿','¿'], zero_division=0))\n",
    "\n",
    "    print(\"Final punctuation per-class F1:\")\n",
    "    print(classification_report(all_final_trues, all_final_preds,\n",
    "                                labels=[0,1,2,3],\n",
    "                                target_names=['none','.', '?', ','], zero_division=0))\n",
    "\n",
    "    print(\"Capitalization per-class F1:\")\n",
    "    print(classification_report(all_cap_trues, all_cap_preds,\n",
    "                                labels=[0,1,2,3],\n",
    "                                target_names=['lower','Initial','Mixed','ALLCAP'], zero_division=0))\n",
    "\n",
    "    print(\"-\"*60) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ba77c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote predictions.csv\n",
      "Test set performance:\n",
      "  • Initial punctuation F1-macro: 0.8481\n",
      "  • Final punctuation   F1-macro: 0.8054\n",
      "  • Capitalization      F1-macro: 0.9128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model.eval()\n",
    "output_rows = []\n",
    "\n",
    "# For metric accumulation\n",
    "all_init_trues,  all_init_preds  = [], [] \n",
    "all_final_trues, all_final_preds = [], []\n",
    "all_cap_trues,   all_cap_preds   = [], []\n",
    "\n",
    "idx_map_init    = {0:'', 1:'¿'}\n",
    "idx_map_final   = {0:'', 1:'.', 2:'?', 3:','}\n",
    "\n",
    "for inst_id, instance in enumerate(test_data):\n",
    "    # prepare inputs\n",
    "    input_ids = torch.tensor(instance[\"input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        init_logits, final_logits, cap_logits = model(input_ids)\n",
    "\n",
    "    # get token-level preds\n",
    "    init_pred  = init_logits.argmax(dim=-1).squeeze(0).cpu().tolist()\n",
    "    final_pred = final_logits.argmax(dim=-1).squeeze(0).cpu().tolist()\n",
    "    cap_pred   = cap_logits.argmax(dim=-1).squeeze(0).cpu().tolist()\n",
    "\n",
    "    # retrieve true labels\n",
    "    init_true  = instance[\"init_labels\"]\n",
    "    final_true = instance[\"final_labels\"]\n",
    "    cap_true   = instance[\"cap_labels\"]\n",
    "    tokens     = instance[\"tokens\"]\n",
    "\n",
    "    # sanity check\n",
    "    assert len(init_pred)==len(init_true)==len(tokens)\n",
    "\n",
    "    # accumulate and record\n",
    "    for token_idx, token in enumerate(tokens):\n",
    "        # append to CSV rows\n",
    "        output_rows.append({\n",
    "            \"instancia_id\": inst_id,\n",
    "            \"token_id\":     token_idx,\n",
    "            \"token\":        token,\n",
    "            \"punt_inicial\": idx_map_init[init_pred[token_idx]],\n",
    "            \"punt_final\":   idx_map_final[final_pred[token_idx]],\n",
    "            \"capitalizacion\": cap_pred[token_idx]\n",
    "        })\n",
    "        # accumulate for metrics\n",
    "        all_init_trues.append(init_true[token_idx])\n",
    "        all_init_preds.append(init_pred[token_idx])\n",
    "        all_final_trues.append(final_true[token_idx])\n",
    "        all_final_preds.append(final_pred[token_idx])\n",
    "        all_cap_trues.append(cap_true[token_idx])\n",
    "        all_cap_preds.append(cap_pred[token_idx])\n",
    "\n",
    "# build and save DataFrame\n",
    "output_df = pd.DataFrame(output_rows)\n",
    "output_df.to_csv(\"predictions.csv\", index=False)\n",
    "print(\"Wrote predictions.csv\")\n",
    "\n",
    "# compute and print macro-F1 for each task\n",
    "f1_init  = f1_score(all_init_trues,  all_init_preds,  average=\"macro\", zero_division=0)\n",
    "f1_final = f1_score(all_final_trues, all_final_preds, average=\"macro\", zero_division=0)\n",
    "f1_cap   = f1_score(all_cap_trues,   all_cap_preds,   average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"Test set performance:\")\n",
    "print(f\"  • Initial punctuation F1-macro: {f1_init:.4f}\")\n",
    "print(f\"  • Final punctuation   F1-macro: {f1_final:.4f}\")\n",
    "print(f\"  • Capitalization      F1-macro: {f1_cap:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
